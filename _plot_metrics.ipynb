{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics for different runs and plot them\n",
    "##### author: Elizabeth A. Barnes, Randal J. Barnes and Mark DeMaria\n",
    "##### version: v0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import experiment_settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from build_data import build_hurricane_data\n",
    "import model_diagnostics\n",
    "import prediction\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dpiFig = 400\n",
    "\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 150\n",
    "np.warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Randal J Barnes and Elizabeth A. Barnes\"\n",
    "__version__ = \"18 March 2022\"\n",
    "\n",
    "EXP_NAME_LIST = (\n",
    "                 \"intensity201_AL24\",\n",
    "                 \"intensity202_AL48\",    \n",
    "                 \"intensity203_AL72\",\n",
    "                 \"intensity204_AL96\",    \n",
    "                 \"intensity205_AL120\",    \n",
    "    \n",
    "                 \"intensity301_EPCP24\",\n",
    "                 \"intensity302_EPCP48\", \n",
    "                 # \"intensity702_EPCP48\", \n",
    "                 \"intensity303_EPCP72\",\n",
    "                 \"intensity304_EPCP96\",    \n",
    "                 \"intensity305_EPCP120\",        \n",
    "                 )\n",
    "\n",
    "APPEND_NAME = ''#'_paper'\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "MODEL_PATH = \"saved_models/\"\n",
    "METRIC_PATH = \"saved_metrics/\"\n",
    "FIGURE_PATH = \"figures/paper_figures/\"\n",
    "PREDICTION_PATH = \"saved_predictions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 16\n",
    "\n",
    "### for white background...\n",
    "plt.rc('text',usetex=True)\n",
    "plt.rc('font',**{'family':'sans-serif','sans-serif':['Avant Garde']}) \n",
    "plt.rc('savefig',facecolor='white')\n",
    "plt.rc('axes',facecolor='white')\n",
    "plt.rc('axes',labelcolor='dimgrey')\n",
    "plt.rc('axes',labelcolor='dimgrey')\n",
    "plt.rc('xtick',color='dimgrey')\n",
    "plt.rc('ytick',color='dimgrey')\n",
    "################################  \n",
    "################################  \n",
    "def adjust_spines(ax, spines):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in spines:\n",
    "            spine.set_position(('outward', 5))\n",
    "        else:\n",
    "            spine.set_color('none')  \n",
    "    if 'left' in spines:\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "    else:\n",
    "        ax.yaxis.set_ticks([])\n",
    "    if 'bottom' in spines:\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "    else:\n",
    "        ax.xaxis.set_ticks([]) \n",
    "\n",
    "def format_spines(ax):\n",
    "    adjust_spines(ax, ['left', 'bottom'])\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['left'].set_color('dimgrey')\n",
    "    ax.spines['bottom'].set_color('dimgrey')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.tick_params('both',length=4,width=2,which='major',color='dimgrey')\n",
    "#     ax.yaxis.grid(zorder=1,color='dimgrey',alpha=0.35)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sample Sizes for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for exp_name in EXP_NAME_LIST:\n",
    "    settings = experiment_settings.get_settings(exp_name)\n",
    "\n",
    "    TESTING_YEARS = 2020\n",
    "    settings[\"years_test\"] = (TESTING_YEARS,)\n",
    "    \n",
    "    RNG_SEED = 416\n",
    "    settings['rng_seed'] = RNG_SEED\n",
    "    seed_dict = {}\n",
    "    \n",
    "    NETWORK_SEED_LIST = [settings[\"rng_seed\"]]\n",
    "    network_seed = NETWORK_SEED_LIST[0]\n",
    "    tf.random.set_seed(network_seed)  # This sets the global random seed.  \n",
    "\n",
    "    # get the data\n",
    "    (\n",
    "        data_summary,        \n",
    "        x_train,\n",
    "        onehot_train,\n",
    "        x_val,\n",
    "        onehot_val,\n",
    "        x_test,\n",
    "        onehot_test,        \n",
    "        x_valtest,\n",
    "        onehot_valtest,\n",
    "        df_train,\n",
    "        df_val,\n",
    "        df_test,\n",
    "        df_valtest,\n",
    "    ) = build_hurricane_data(DATA_PATH, settings, verbose=0)\n",
    "    \n",
    "    print(exp_name + ' ' + str(np.shape(x_train)[0]) + ' ' + str(np.shape(x_val)[0]) + ' ' + str(np.shape(x_test)[0]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for exp_name in EXP_NAME_LIST:\n",
    "    settings = experiment_settings.get_settings(exp_name)\n",
    "\n",
    "    # set testing data\n",
    "    if settings[\"test_condition\"] == \"leave-one-out\":\n",
    "        TESTING_YEARS_LIST = np.arange(2013,2022)\n",
    "    elif settings[\"test_condition\"] == \"years\":\n",
    "        TESTING_YEARS_LIST = (np.copy(settings[\"years_test\"]))\n",
    "    else:\n",
    "        raise NotImplementError('no such testing condition')\n",
    "        \n",
    "        \n",
    "    for testing_years in TESTING_YEARS_LIST:        \n",
    "        # set testing year\n",
    "        settings[\"years_test\"] = (testing_years,)\n",
    "    \n",
    "    \n",
    "        for rng_seed in settings[\"rng_seed_list\"]:\n",
    "            settings['rng_seed'] = rng_seed\n",
    "            NETWORK_SEED_LIST = [settings[\"rng_seed\"]]\n",
    "            network_seed = NETWORK_SEED_LIST[0]\n",
    "\n",
    "            model_name = (\n",
    "                exp_name + \"_\" + \n",
    "                str(testing_years) + '_' +\n",
    "                settings[\"uncertainty_type\"] + '_' + \n",
    "                f\"network_seed_{network_seed}_rng_seed_{settings['rng_seed']}\"\n",
    "            )\n",
    "\n",
    "            # load the metric filename\n",
    "            metric_filename = METRIC_PATH + model_name + '_metrics.pickle'  \n",
    "            if os.path.exists(metric_filename)==False:\n",
    "                metric_filename = METRIC_PATH + model_name + '_metrics.pkl'  \n",
    "                if os.path.exists(metric_filename)==False:\n",
    "                    print(metric_filename + ' DOES NOT exist. Skipping...')\n",
    "                    continue\n",
    "\n",
    "            # pprint.pprint(model_name)\n",
    "            df = pd.read_pickle(metric_filename)\n",
    "            # print(\"***remove these***\")\n",
    "            # df['basin_lead'] = exp_name[exp_name.rfind('_')+1:]\n",
    "            # df['testing_years'] = settings[\"years_test\"]\n",
    "\n",
    "            df_metrics = pd.concat([df_metrics,df])\n",
    "# get best validation results            \n",
    "idx = df_metrics.groupby(['exp_name', 'testing_years'], sort=False)['median_error_reduction_val'].transform(max) == df_metrics['median_error_reduction_val']\n",
    "df_metrics_bestval = df_metrics[idx]\n",
    "\n",
    "BEST_VAL_ONLY = True\n",
    "if BEST_VAL_ONLY:\n",
    "    print(\"**plotting only the best seed for validation error reductions**\")\n",
    "    APPEND_NAME = ''\n",
    "    df_metrics = df_metrics[idx]\n",
    "    df_bestval = df_metrics[[\"exp_name\",\"basin_lead\",\"testing_years\",\"rng_seed\",\"network_seed\"]]\n",
    "    df_bestval.to_pickle(PREDICTION_PATH + \"best_shash3_validation_seeds.pickle\")\n",
    "else:\n",
    "    APPEND_NAME = APPEND_NAME + \"_allNetworks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Major summary for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[df_metrics[\"exp_name\"]==\"intensity302_EPCP48\"][\"iqr_error_spearman_valtest\"]#[\"iqr_capture_valtest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_SUMMARY = False\n",
    "if SHOW_SUMMARY:\n",
    "    colors = ('#284E60','#E1A730','#C3B1E1')\n",
    "\n",
    "    x_axis_list = (\"exp_name\",)#(\"basin_lead\",)#(\"basin_lead\", \"exp_name\")\n",
    "\n",
    "    metric_list = ('mean_error',\n",
    "                  'mean_error_reduction',\n",
    "                  'median_error',\n",
    "                  'median_error_reduction',                                                                        \n",
    "                  'iqr_error_spearman',\n",
    "                  'mode_error_reduction',                                                                        \n",
    "                  # 'iqr_error_pearson',                                  \n",
    "                  # 'mode_error',\n",
    "                  'pit_D',\n",
    "                  'iqr_capture')\n",
    "    metric_data = '_test'\n",
    "\n",
    "    for x_axis in x_axis_list:\n",
    "        f, axs = plt.subplots(4, 2, figsize=(15,20))\n",
    "        axs = axs.flatten()\n",
    "\n",
    "        for imetric, metric in enumerate([m + metric_data for m in metric_list]):\n",
    "            ax = axs[imetric]\n",
    "            g1 = sns.boxplot(x=x_axis, \n",
    "                             y=metric, \n",
    "                             hue=\"uncertainty_type\",\n",
    "                             data=df_metrics,\n",
    "                             palette=colors,\n",
    "                             boxprops={'alpha':.2,\n",
    "                                       'edgecolor': 'white',\n",
    "                                      },\n",
    "                             fliersize=0,\n",
    "                             ax=ax)\n",
    "            g2 = sns.swarmplot(x=x_axis, \n",
    "                               y=metric, \n",
    "                               hue=\"uncertainty_type\",\n",
    "                               palette=colors,\n",
    "                               data=df_metrics, \n",
    "                               dodge=True,\n",
    "                               ax=ax)\n",
    "\n",
    "            if(metric=='iqr_capture'):\n",
    "                ax.axhline(y=0.5,linewidth=3,linestyle='--',color='gray')\n",
    "                ax.set_ylim(0,1.0)\n",
    "            if(metric=='pit_d'):\n",
    "                ax.set_ylim(0,None)\n",
    "            if(metric.find('reduction') > -1):\n",
    "                ax.axhline(y=0.0,linewidth=3,linestyle='--',color='gray')\n",
    "                ax.set_ylim(-4.,4.)\n",
    "            if(metric.find('reduction') == -1 and metric.find('n_error') > -1):\n",
    "                ax.set_ylim(0.,22.)\n",
    "            if(metric.find('iqr_error')> -1):\n",
    "                ax.set_ylim(-.3,1.)\n",
    "                ax.axhline(y=0.0,linewidth=3,linestyle='--',color='gray')        \n",
    "\n",
    "\n",
    "            ax.set_title(metric + APPEND_NAME)\n",
    "            ax.legend(fontsize=10,frameon=True)\n",
    "            ax.set_xticklabels(ax.get_xticklabels(),rotation = 30)\n",
    "\n",
    "        plt.tight_layout()    \n",
    "        # plt.savefig(FIGURE_PATH + 'comparisonsMetrics' + APPEND_NAME + '_' + x_axis + '.png', dpi=dpiFig)    \n",
    "        # plt.close()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure for main paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_A = 10\n",
    "colors = ('#D95980','#284E60','#E1A730','#C3B1E1','#351F27','#A9C961')\n",
    "panel_letters = ('(a)','(b)','(c)','(d)')\n",
    "x_axis_list = (\"basin_lead\",)#(\"basin_lead\", \"exp_name\")\n",
    "\n",
    "metric_data = ''\n",
    "metric_list = ('median_error_reduction_test',\n",
    "               'pit_D_valtest',\n",
    "               'iqr_error_spearman_valtest',                                                                     \n",
    "               'iqr_capture_valtest',\n",
    "              )\n",
    "title_text = ('(a) error reduction (knots)',\n",
    "              '(b) PIT D',\n",
    "              '(c) IQR vs error correlation',\n",
    "              '(d) IQR capture fraction',\n",
    "             )\n",
    "\n",
    "for x_axis in x_axis_list:\n",
    "    f, axs = plt.subplots(2, 2, figsize=(15/1.25,10/1.25))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for imetric, metric in enumerate([m + metric_data for m in metric_list]):\n",
    "        ax = axs[imetric]\n",
    "        g1 = sns.boxplot(x=x_axis, \n",
    "                         y=metric, \n",
    "                         hue=\"exp_name\",\n",
    "                         data=df_metrics,\n",
    "                         palette=colors,\n",
    "                         width=.75,\n",
    "                         dodge=False,\n",
    "                         boxprops={'alpha':.2,\n",
    "                                   'edgecolor': 'white',\n",
    "                                  },\n",
    "                         fliersize=0,\n",
    "                         ax=ax)\n",
    "        g2 = sns.swarmplot(x=x_axis, \n",
    "                           y=metric, \n",
    "                           hue=\"exp_name\",\n",
    "                           palette=colors,\n",
    "                           data=df_metrics, \n",
    "                           dodge=False,\n",
    "                           size=5,\n",
    "                           ax=ax)\n",
    "\n",
    "        if(metric.find('iqr_capture') > -1):\n",
    "            ax.axhline(y=0.5,linewidth=3,linestyle='--',color='gray')\n",
    "            ax.set_ylim(0,1.0)\n",
    "        if(metric.find('pit_D') > -1):\n",
    "            ax.set_ylim(0,.1)\n",
    "        if(metric.find('reduction') > -1):\n",
    "            ax.axhline(y=0.0,linewidth=3,linestyle='--',color='gray')\n",
    "            ax.set_ylim(-5.5,5.5)\n",
    "        if(metric.find('reduction') == -1 and metric.find('n_error') > -1):\n",
    "            ax.set_ylim(0.,22.)\n",
    "        if(metric.find('iqr_error')> -1):\n",
    "            ax.set_ylim(-.3,1.)\n",
    "            ax.axhline(y=0.0,linewidth=3,linestyle='--',color='gray')        \n",
    "\n",
    "        ax.set_title(title_text[imetric],\n",
    "                     fontsize=FS,\n",
    "                     color='k',\n",
    "                    )\n",
    "            \n",
    "#         ax.set_title(panel_letters[imetric] + ' ' + metric + APPEND_NAME,\n",
    "#                      fontsize=FS,\n",
    "#                      color='k',\n",
    "#                     )\n",
    "        # ax.legend(fontsize=10,frameon=True)\n",
    "        ax.get_legend().remove()\n",
    "        x_tick_labels = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(x_tick_labels,rotation = 30)\n",
    "        yticks = np.around(ax.get_yticks(),3)\n",
    "        ax.set_yticklabels(yticks)       \n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        format_spines(ax)\n",
    "        ax.set_xticklabels(x_tick_labels,rotation = 30)\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "    plt.tight_layout()    \n",
    "    # plt.savefig(FIGURE_PATH + 'comparisonsMetrics' + APPEND_NAME + '.png', dpi=dpiFig)    \n",
    "    # plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error('STOPPING FOR SHASH-TFP TESTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics[df_metrics[\"exp_name\"]==\"intensity302_EPCP48\"][[\"testing_years\",\"median_error_reduction_val\",\"median_error_reduction_test\", \"rng_seed\"]]\n",
    "# for exp_name in df_metrics[\"exp_name\"].unique():\n",
    "#     df_show = df_metrics.loc[df_metrics[\"exp_name\"]==exp_name][[\"exp_name\",\n",
    "#                                                                 \"testing_years\",                                                                \n",
    "#                                                                 \"network_seed\", \n",
    "#                                                                 # \"mode_error_reduction_val\",\n",
    "#                                                                 \"median_error_reduction_val\",\n",
    "#                                                                 \"median_error_reduction_test\",                                                                \n",
    "#                                                                ]]\n",
    "#     display(df_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum = np.cumsum(obs_dev_cons_hist)\n",
    "# ilow = np.argmin(np.abs(cumsum-.25))\n",
    "# ihigh = np.argmin(np.abs(cumsum-.75))\n",
    "# OBS_DEV_BINS[ihigh]-OBS_DEV_BINS[ilow]\n",
    "\n",
    "# print(OBS_DEV_BINS[ilow],OBS_DEV_BINS[ihigh])\n",
    "\n",
    "# plt.plot(OBS_DEV_BINS,obs_dev_cons_hist)\n",
    "\n",
    "raise Warning('this does not make much sense since a wider Climo would make consensus look better')\n",
    "\n",
    "df_bestpred = pd.read_csv(PREDICTION_PATH + \"shash3_bestValTestingPredictions.csv\")\n",
    "\n",
    "df = df_bestpred[\n",
    "    (df_bestpred[\"ATCF\"].str.contains('AL')) &\n",
    "    (df_bestpred[\"ftime(hr)\"]==24)\n",
    "]\n",
    "\n",
    "weight = df['shash_75p'] - df['shash_25p']\n",
    "weighted_error = df['shash_error']/weight#/np.sum(weight)\n",
    "\n",
    "cons_weight = np.ones(np.shape(df['cons_error'])[0])*22\n",
    "weighted_cons_error = df['cons_error']/cons_weight#/np.sum(cons_weight)\n",
    "\n",
    "print('SHASH weighted error     = ' + str(np.mean(np.abs(weighted_error)).round(3)))\n",
    "print('Consensus weighted error = ' + str(np.mean(np.abs(weighted_cons_error)).round(3)))\n",
    "\n",
    "sns.kdeplot(weighted_error,label='shash')\n",
    "sns.kdeplot(weighted_cons_error,color='orange',label='consensus+climo')\n",
    "plt.xlabel('scaled error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bestpred = pd.read_csv(PREDICTION_PATH + \"shash3_bestValTestingPredictions.csv\")\n",
    "\n",
    "# df = df_bestpred[\n",
    "#     (df_bestpred[\"ATCF\"].str.contains('AL')) &\n",
    "#     (df_bestpred[\"ftime(hr)\"]==24)\n",
    "# ]\n",
    "\n",
    "\n",
    "# weighted_error = np.mean(np.abs(df['shash_error']))\n",
    "\n",
    "# weighted_cons_error = np.mean(np.abs(df['cons_error']))\n",
    "\n",
    "# print('SHASH weighted error     = ' + str(weighted_error.round(3)))\n",
    "# print('Consensus weighted error = ' + str(weighted_cons_error.round(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
